{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AC_Gxeu4UcJ"
      },
      "source": [
        "# Gemma 3n - Function Calling: Local File Reader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlsJnFBYSrkZ"
      },
      "source": [
        "Google released Gemma 3n, a compact generative AI model optimized for everyday devices like phones and laptops. It supports multimodal inputs (image + audio) and offers multilingual capabilities across numerous languages. Though smaller than its larger siblings, Gemma 3n enables efficient function calling for structured responses. In this notebook, we‚Äôll explore how to leverage Gemma 3n via Hugging Face Transformers to read and summarize local text files using its function-calling abilities.\n",
        "\n",
        "## Setup\n",
        "\n",
        "Before starting this tutorial, complete the following steps:\n",
        "\n",
        "* Get access to Gemma by logging into [Hugging Face](https://huggingface.co/google/gemma-3n-E4b-it) and selecting **Acknowledge license** for a Gemma model.\n",
        "* Select a Colab runtime with sufficient resources to run\n",
        "  the Gemma model size you want to run. [Learn more](https://ai.google.dev/gemma/docs/core#sizes).\n",
        "* Generate a Hugging Face [Access Token](https://huggingface.co/docs/hub/en/security-tokens#how-to-manage-user-access-token) and use it to login from Colab.\n",
        "\n",
        "This notebook will run on an NVIDIA T4 GPU using Gemma 3n E2B.\\\n",
        "But if you want to use Gemma 3n E4B, select L4 or A100.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ogSB3peYP1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "3774e969085048c791a1cab4a89db3dd",
            "236b876ba5dd493a8c9bf5ada2043cd0",
            "b66b20aabdf3451fa7272d6ad4b66925",
            "ba8dd4fdcf084f7bb225e9a9a548bc5c",
            "b6e76c3f4ccc4dc58c4ed0ba80b0eb31",
            "175bfde861314f7aa90a8636728bade4",
            "eb58eb03efdb47ae8962666915241473",
            "3bdeb683c626431e83719a8518327726",
            "d1ed91fa505e4d818f1e388a4a53a920",
            "b375c75804564f1fb0ca614203a861f6",
            "b60c2e0063b04240a4e8a1a8ce6bd35e",
            "3e90693fffef41849f3dddfe2b63021e",
            "fa994a12aa214ba7abc4cb2fbdc3fb62",
            "01f1fb2c0d15458ab93e674e87863db6",
            "332f4c7ecf6249398e94f236ad6a75a6",
            "ff284d90dded47148be30f7b1b7c6ae3",
            "8d7104048e3f461e95f724ff6a839362",
            "347c5bff3fed45d0b5f1d897559c4c82",
            "e35c2bafb9eb4af5a2a18b4188f42289",
            "7c3af200d0144ccb8523514c4f239911"
          ]
        },
        "outputId": "e2695ce6-cda4-45ff-fdcd-ec4393b5cf25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3774e969085048c791a1cab4a89db3dd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Login into Hugging Face Hub\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RgrZH4cP1b4"
      },
      "source": [
        "### Install Python packages\n",
        "\n",
        "Install the Hugging Face libraries required for running the Gemma model and making requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty1cuOpoP1b4"
      },
      "outputs": [],
      "source": [
        "# Install a transformers version that supports Gemma 3n (>= 4.53)\n",
        "!pip install \"transformers>=4.53.0\" \"timm>=1.0.16\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mafyLFuD3WvW"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nsYlh_WK3YKb",
        "outputId": "d07396fc-4e28-42d8-f566-a37c50481a08",
        "colab": {
          "referenced_widgets": [
            "f2643e763f43482d94c47b024d3869af",
            "1e7d5d43fd5a4223a97e5017011f2af8",
            "c1052b0f8bac4127bb08b225acad100d",
            "ca90c9e95a7642aab4f1e31cd3cd0853",
            "563039305ac6450493fad1cdc5041a07",
            "1aa06499029d44e2ab32857cb44236c0",
            "aa73b9b5ef2b4e738fe5bd084c07b511",
            "534c096aed2d4eb29996af34b403c1a1",
            "e1640fbfd0764d0a97ff65380030ab26",
            "83142e10a997419c84fb0443f45736a5",
            "79473b3c2b37456983ae0e832c8874bb"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2643e763f43482d94c47b024d3869af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "DType: torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
        "import torch\n",
        "\n",
        "GEMMA_PATH = \"google/gemma-3n-E2B-it\" #@param [\"google/gemma-3n-E2B-it\", \"google/gemma-3n-E4B-it\"]\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(GEMMA_PATH)\n",
        "model = AutoModelForImageTextToText.from_pretrained(GEMMA_PATH, torch_dtype=\"auto\", device_map=\"auto\")\n",
        "\n",
        "print(f\"Device: {model.device}\")\n",
        "print(f\"DType: {model.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "bdP-RnFb8Wo9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling Gemma 3n\n",
        "Function calling lets language models interact with tools and systems through structured commands. In this example, we use Gemma 3n to read and summarize a local file (e.g., notes.txt) uploaded to Colab using this feature."
      ],
      "metadata": {
        "id": "btEPErNjxErC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filename: str) -> str:\n",
        "    \"\"\"\n",
        "    Reads the contents of a local text file and returns it as a string.\n",
        "\n",
        "    Args:\n",
        "        filename: The name of the file to read (e.g., 'notes.txt')\n",
        "    Returns:\n",
        "        The contents of the file as a string, or an error message if the file is not found.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: File '{filename}' not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "RPFWpqkpxG5_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of available tools\n",
        "tools = [read_file]"
      ],
      "metadata": {
        "id": "ZfWTet2RVEsz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Extraction and Execution\n",
        "\n",
        "When models generate code inside text, extracting and safely running that code lets us connect AI with real tools.\n",
        "This code snippet shows how to extract and run Python code embedded in text generated by the model.\n"
      ],
      "metadata": {
        "id": "KvV3hykieR2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "def extract_tool_call(text):\n",
        "    \"\"\"\n",
        "    Extracts and executes tool_code from the model-generated text\n",
        "    \"\"\"\n",
        "    pattern = r\"```tool_code\\s*(.*?)\\s*```\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        code = match.group(1).strip()\n",
        "        print(f\"üìã Extracted code:\\n{code}\")\n",
        "\n",
        "        # Capture stdout in a string buffer\n",
        "        f = io.StringIO()\n",
        "        with redirect_stdout(f):\n",
        "            # Execute code with available tools in namespace\n",
        "            exec(code, {\"read_file\": read_file})\n",
        "\n",
        "        output = f.getvalue()\n",
        "\n",
        "        # If there's print output, use it; otherwise look for variables in local namespace\n",
        "        if output.strip():\n",
        "            result = f'```tool_output\\n{output.strip()}\\n```'\n",
        "        else:\n",
        "            # Try to evaluate the code to get the result\n",
        "            try:\n",
        "                result_eval = eval(code, {\"read_file\": read_file})\n",
        "                result = f'```tool_output\\n{result_eval}\\n```'\n",
        "            except:\n",
        "                result = f'```tool_output\\nTool executed successfully\\n```'\n",
        "\n",
        "        print(f\"‚úÖ Tool result:\\n{result}\")\n",
        "        return result\n",
        "\n",
        "    print(\"‚ùå No tool_code found in response\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "1dQxLXpcHl8X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ChatState Class  \n",
        "Creates a chat helper to manage conversation history, send messages to the model, and process responses including tool outputs."
      ],
      "metadata": {
        "id": "AIKB0Kycgtyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatState():\n",
        "    def __init__(self, model, processor):\n",
        "        self.model = model\n",
        "        self.processor = processor\n",
        "        self.history = []\n",
        "\n",
        "    def send_message(self, message, max_tokens=512):\n",
        "        \"\"\"\n",
        "        Sends message and gets response with possible tool call\n",
        "        \"\"\"\n",
        "        self.history.append(message)\n",
        "\n",
        "        input_ids = self.processor.apply_chat_template(\n",
        "            self.history,\n",
        "            tools=tools,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=True,\n",
        "            return_dict=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_len = input_ids[\"input_ids\"].shape[-1]\n",
        "        input_ids = input_ids.to(self.model.device)\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            **input_ids,\n",
        "            max_new_tokens=max_tokens,\n",
        "            disable_compile=True,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=self.processor.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        response_text = self.processor.batch_decode(\n",
        "            outputs[:, input_len:],\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=True\n",
        "        )[0]\n",
        "\n",
        "        # Add response to history\n",
        "        self.history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": response_text}]\n",
        "        })\n",
        "\n",
        "        return response_text\n",
        "\n",
        "    def process_tool_result_and_respond(self, tool_result, original_query, max_tokens=512):\n",
        "        \"\"\"\n",
        "        Processes tool result and generates final response\n",
        "        \"\"\"\n",
        "\n",
        "        # Create new prompt with tool result\n",
        "        prompt = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"Results from the file read:{tool_result} User_query: {original_query}\"}\n",
        "            ]\n",
        "        }]\n",
        "\n",
        "        final_prompt = self.processor.apply_chat_template(\n",
        "            prompt,\n",
        "            tools=tools,\n",
        "            add_generation_prompt=True,\n",
        "            return_dict=True,\n",
        "            tokenize=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(self.model.device, dtype=torch.bfloat16)\n",
        "\n",
        "        response = self.model.generate(\n",
        "            **final_prompt,\n",
        "            max_new_tokens=max_tokens,\n",
        "            disable_compile=True,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=self.processor.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        final_response = self.processor.decode(response[0], skip_special_tokens=True)\n",
        "        return final_response"
      ],
      "metadata": {
        "id": "PDzwMS2pHyX1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define prompt for function calling\n",
        "Orchestrates a two-step flow: first prompts the model to generate a code snippet using available tools, then executes it and builds a final response based on the output."
      ],
      "metadata": {
        "id": "ojWd39Jodut-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file_query(chat_state, query):\n",
        "    \"\"\"\n",
        "    Processes a file query using the 2-step flow:\n",
        "    1. Generates tool_code\n",
        "    2. Executes the code and generates final response\n",
        "    \"\"\"\n",
        "\n",
        "    # Create initial conversation with system instructions\n",
        "\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": \"\"\"\n",
        "            You are an expert file assistant. Use `read_file` to access and process local text files.\n",
        "            At each turn, if you decide to invoke any of the function(s), it should be wrapped with ```tool_code```. The Python methods described below are imported and available,\n",
        "            you can only use defined methods. The generated code should be readable and efficient. The response to a method will be wrapped in ```tool_output```; use it to call more tools or generate a helpful, friendly response.\n",
        "            When using a ```tool_call```, think step by step why and how it should be used.\n",
        "\n",
        "            The following Python methods are available:\n",
        "            ```python\n",
        "            def read_file(filename: str) -> str:\n",
        "              \"\n",
        "              Reads the contents of a local text file and returns it as a string.\n",
        "\n",
        "              Args:\n",
        "                  filename: The name of the file to read (e.g., 'notes.txt')\n",
        "              Returns:\n",
        "                  The contents of the file as a string, or an error message if the file is not found.\n",
        "              \"\n",
        "            ```\n",
        "\n",
        "            User: {user_message}\n",
        "            \"\"\"}]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": query}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Step 1: Generate tool_code\n",
        "    print(\"=== üîÑ STEP 1: Generating tool_code ===\")\n",
        "    response = chat_state.send_message(conversation)  # Only user message\n",
        "    print(\"üìù Initial response:\")\n",
        "    print(response)\n",
        "\n",
        "    # Step 2: Extract and execute tool_code\n",
        "    print(\"\\n=== ‚öôÔ∏è STEP 2: Executing tool_code ===\")\n",
        "    tool_result = extract_tool_call(response)\n",
        "\n",
        "    if tool_result:\n",
        "        print(\"‚úÖ Tool executed successfully\")\n",
        "\n",
        "        # Step 3: Generate final response\n",
        "        print(\"\\n=== üéØ STEP 3: Generating final response ===\")\n",
        "        final_response = chat_state.process_tool_result_and_respond(tool_result, query)\n",
        "        print(\"üìã Final response:\")\n",
        "        print(final_response)\n",
        "\n",
        "        return final_response\n",
        "    else:\n",
        "        print(\"‚ùå No tool_code found in response\")\n",
        "        return response"
      ],
      "metadata": {
        "id": "-ksSseGBH4SH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload your file  \n",
        "Before interacting with the model, you can upload any `.txt` file to the environment. In this example, we‚Äôll use this [sample file](https://huggingface.co/datasets/daqc/demo-data/resolve/main/gemma-3n/notes.txt).\n"
      ],
      "metadata": {
        "id": "IR-y7brWmzoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload file to Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üìÅ Upload your notes.txt file (or any .txt file):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verify the file was uploaded correctly\n",
        "import os\n",
        "print(\"üìã Available files:\")\n",
        "for filename in os.listdir('.'):\n",
        "    if filename.endswith('.txt'):\n",
        "        print(f\"  ‚úÖ {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "5uRR4rVjIDCB",
        "outputId": "8dac56f3-eac8-4f88-a197-f36a07b9e9ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Upload your notes.txt file (or any .txt file):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ca3777f-2a77-4702-8410-3cfb3f8f1d10\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ca3777f-2a77-4702-8410-3cfb3f8f1d10\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving notes.txt to notes.txt\n",
            "üìã Available files:\n",
            "  ‚úÖ notes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your function calling\n",
        "\n",
        "The function calling process works like this:\n",
        "\n",
        "1. The application sends a prompt and function definitions, including the user query, to the LLM.\n",
        "2. The LLM decides whether to respond directly or generate a structured function call with arguments.\n",
        "3. The application extracts and executes the function call.\n",
        "4. The execution results are sent back to the LLM.\n",
        "5. The LLM creates a final response using the function output and the original query.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l_UdComOoEPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create chat instance\n",
        "chat = ChatState(model, processor)"
      ],
      "metadata": {
        "id": "8k2WM0ScIIXR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the query\n",
        "query = \"Summarize the contents of notes.txt\"\n",
        "\n",
        "print(f\"üîç Executing query: '{query}'\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Process the query\n",
        "result = process_file_query(chat, query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxGQW_0IOx3",
        "outputId": "8ae43ba2-0a70-4311-9619-274fb6fb5fd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Executing query: 'Summarize the contents of notes.txt'\n",
            "==================================================\n",
            "=== üîÑ STEP 1: Generating tool_code ===\n",
            "üìù Initial response:\n",
            "I need to read the contents of the file \"notes.txt\" to summarize it. I will use the `read_file` function for this purpose.\n",
            "```tool_code\n",
            "print(read_file(\"notes.txt\"))\n",
            "```\n",
            "\n",
            "=== ‚öôÔ∏è STEP 2: Executing tool_code ===\n",
            "üìã Extracted code:\n",
            "print(read_file(\"notes.txt\"))\n",
            "‚úÖ Tool result:\n",
            "```tool_output\n",
            "The Way of Code ‚Äì A Taoist Manifesto for Developers\n",
            "\n",
            "The Way of Code is a minimalist, poetic guide to programming, created as a collaboration between music producer Rick Rubin and Claude, the AI developed by Anthropic. Presented as a digital meditation, it reimagines software development through the lens of Taoist philosophy, echoing the spirit of the Tao Te Ching. It introduces the idea of ‚Äúvibe coding‚Äù‚Äîa gentle, ego-free way of creating software that prioritizes intuition, presence, and flow over rigid structure or performance metrics. Each short passage encourages stillness, simplicity, and letting go of control, suggesting that great code emerges from alignment with a deeper creative source. Rather than teaching programming techniques, it invites reflection, proposing that software‚Äîlike music, poetry, or any true art‚Äîshould be felt as much as it is engineered. Rubin‚Äôs influence adds a grounded, artistic sensibility, while Claude lends a modern, contemplative AI voice‚Äîoffering a fresh and timeless perspective on coding in the 21st century.\n",
            "```\n",
            "‚úÖ Tool executed successfully\n",
            "\n",
            "=== üéØ STEP 3: Generating final response ===\n",
            "üìã Final response:\n",
            "user\n",
            "Results from the file read:```tool_output\n",
            "The Way of Code ‚Äì A Taoist Manifesto for Developers\n",
            "\n",
            "The Way of Code is a minimalist, poetic guide to programming, created as a collaboration between music producer Rick Rubin and Claude, the AI developed by Anthropic. Presented as a digital meditation, it reimagines software development through the lens of Taoist philosophy, echoing the spirit of the Tao Te Ching. It introduces the idea of ‚Äúvibe coding‚Äù‚Äîa gentle, ego-free way of creating software that prioritizes intuition, presence, and flow over rigid structure or performance metrics. Each short passage encourages stillness, simplicity, and letting go of control, suggesting that great code emerges from alignment with a deeper creative source. Rather than teaching programming techniques, it invites reflection, proposing that software‚Äîlike music, poetry, or any true art‚Äîshould be felt as much as it is engineered. Rubin‚Äôs influence adds a grounded, artistic sensibility, while Claude lends a modern, contemplative AI voice‚Äîoffering a fresh and timeless perspective on coding in the 21st century.\n",
            "``` User_query: Summarize the contents of notes.txt\n",
            "model\n",
            "The provided text describes \"The Way of Code,\" a book/guide that blends Taoist philosophy with software development. It advocates for \"vibe coding,\" a non-technical approach emphasizing intuition, flow, and letting go of control in the coding process. The guide encourages reflection and feeling the code rather than focusing on rigid structure or metrics. It's a collaboration between Rick Rubin and the AI Claude, aiming to offer a timeless perspective on coding in the modern era.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f8ff452"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Build and explore more with Gemma 3n models:\n",
        "\n",
        "## Inference\n",
        "\n",
        "* [Multimodal inference using Gemma 3n via pipeline](https://colab.research.google.com/github/huggingface/huggingface-gemma-recipes/blob/main/notebooks/gemma3n_inference_via_pipeline.ipynb)\n",
        "\n",
        "## Fine Tuning\n",
        "\n",
        "* [Fine tuning Gemma 3n 2B on free Colab T4](https://colab.research.google.com/github/huggingface/huggingface-gemma-recipes/blob/main/notebooks/fine_tune_gemma3n_on_t4.ipynb)\n",
        "\n",
        "* [Fine tuning Gemma 3n 4B with Unsloth on free Colab T4](https://colab.research.google.com/github/huggingface/huggingface-gemma-recipes/blob/main/notebooks/Gemma3N_(4B)-Conversational.ipynb)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3774e969085048c791a1cab4a89db3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_eb58eb03efdb47ae8962666915241473"
          }
        },
        "236b876ba5dd493a8c9bf5ada2043cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bdeb683c626431e83719a8518327726",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d1ed91fa505e4d818f1e388a4a53a920",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "b66b20aabdf3451fa7272d6ad4b66925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b375c75804564f1fb0ca614203a861f6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b60c2e0063b04240a4e8a1a8ce6bd35e",
            "value": ""
          }
        },
        "ba8dd4fdcf084f7bb225e9a9a548bc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_3e90693fffef41849f3dddfe2b63021e",
            "style": "IPY_MODEL_fa994a12aa214ba7abc4cb2fbdc3fb62",
            "value": true
          }
        },
        "b6e76c3f4ccc4dc58c4ed0ba80b0eb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_01f1fb2c0d15458ab93e674e87863db6",
            "style": "IPY_MODEL_332f4c7ecf6249398e94f236ad6a75a6",
            "tooltip": ""
          }
        },
        "175bfde861314f7aa90a8636728bade4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff284d90dded47148be30f7b1b7c6ae3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d7104048e3f461e95f724ff6a839362",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "eb58eb03efdb47ae8962666915241473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3bdeb683c626431e83719a8518327726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ed91fa505e4d818f1e388a4a53a920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b375c75804564f1fb0ca614203a861f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60c2e0063b04240a4e8a1a8ce6bd35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e90693fffef41849f3dddfe2b63021e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa994a12aa214ba7abc4cb2fbdc3fb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01f1fb2c0d15458ab93e674e87863db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332f4c7ecf6249398e94f236ad6a75a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ff284d90dded47148be30f7b1b7c6ae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7104048e3f461e95f724ff6a839362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "347c5bff3fed45d0b5f1d897559c4c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35c2bafb9eb4af5a2a18b4188f42289",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7c3af200d0144ccb8523514c4f239911",
            "value": "Connecting..."
          }
        },
        "e35c2bafb9eb4af5a2a18b4188f42289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3af200d0144ccb8523514c4f239911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2643e763f43482d94c47b024d3869af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e7d5d43fd5a4223a97e5017011f2af8",
              "IPY_MODEL_c1052b0f8bac4127bb08b225acad100d",
              "IPY_MODEL_ca90c9e95a7642aab4f1e31cd3cd0853"
            ],
            "layout": "IPY_MODEL_563039305ac6450493fad1cdc5041a07"
          }
        },
        "1e7d5d43fd5a4223a97e5017011f2af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa06499029d44e2ab32857cb44236c0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aa73b9b5ef2b4e738fe5bd084c07b511",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "c1052b0f8bac4127bb08b225acad100d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_534c096aed2d4eb29996af34b403c1a1",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1640fbfd0764d0a97ff65380030ab26",
            "value": 3
          }
        },
        "ca90c9e95a7642aab4f1e31cd3cd0853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83142e10a997419c84fb0443f45736a5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_79473b3c2b37456983ae0e832c8874bb",
            "value": "‚Äá3/3‚Äá[00:44&lt;00:00,‚Äá14.53s/it]"
          }
        },
        "563039305ac6450493fad1cdc5041a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa06499029d44e2ab32857cb44236c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa73b9b5ef2b4e738fe5bd084c07b511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "534c096aed2d4eb29996af34b403c1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1640fbfd0764d0a97ff65380030ab26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83142e10a997419c84fb0443f45736a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79473b3c2b37456983ae0e832c8874bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}